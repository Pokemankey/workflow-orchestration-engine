services:
    kafka:
        image: confluentinc/cp-kafka:7.6.0
        hostname: kafka
        container_name: kafka
        user: root
        ports:
            - '9092:9092'
        environment:
            # KRaft Configuration
            KAFKA_NODE_ID: 1
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
            KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
            KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
            KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
            KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
            KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
            KAFKA_PROCESS_ROLES: 'broker,controller'
            KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
            CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'

            # Topic Configuration
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
            KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'

            # Performance tuning
            KAFKA_NUM_NETWORK_THREADS: 3
            KAFKA_NUM_IO_THREADS: 8
            KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
            KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
            KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600

        volumes:
            - kafka-data:/var/lib/kafka/data
        healthcheck:
            test: ['CMD-SHELL', 'kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1']
            interval: 10s
            timeout: 10s
            retries: 10
            start_period: 40s
        networks:
            - workflow-network

    kafka-init:
        image: confluentinc/cp-kafka:7.6.0
        container_name: kafka-init
        depends_on:
            kafka:
                condition: service_healthy
        environment:
            # Topic configuration - EDIT THESE TO CHANGE PARTITIONS
            WORKFLOW_START_PARTITIONS: ${WORKFLOW_START_PARTITIONS:-3}
            TASK_DISPATCH_PARTITIONS: ${TASK_DISPATCH_PARTITIONS:-3}
            TASK_COMPLETE_PARTITIONS: ${TASK_COMPLETE_PARTITIONS:-3}
        entrypoint: ['/bin/bash', '-c']
        command:
            - |
                echo "Waiting for Kafka to be ready..."
                sleep 10

                echo "Creating Kafka topics..."

                # Create workflow.start topic
                kafka-topics --create \
                  --if-not-exists \
                  --bootstrap-server kafka:29092 \
                  --topic workflow.start \
                  --partitions $${WORKFLOW_START_PARTITIONS} \
                  --replication-factor 1 \
                  --config retention.ms=604800000

                # Create task.dispatch topic
                kafka-topics --create \
                  --if-not-exists \
                  --bootstrap-server kafka:29092 \
                  --topic task.dispatch \
                  --partitions $${TASK_DISPATCH_PARTITIONS} \
                  --replication-factor 1 \
                  --config retention.ms=604800000

                # Create task.complete topic
                kafka-topics --create \
                  --if-not-exists \
                  --bootstrap-server kafka:29092 \
                  --topic task.complete \
                  --partitions $${TASK_COMPLETE_PARTITIONS} \
                  --replication-factor 1 \
                  --config retention.ms=604800000

                echo "Topics created successfully!"

                echo "Listing all topics:"
                kafka-topics --list --bootstrap-server kafka:29092

                echo "Topic details:"
                kafka-topics --describe --bootstrap-server kafka:29092

                echo "Kafka initialization complete!"
        networks:
            - workflow-network

    redis:
        image: redis:7-alpine
        container_name: redis
        ports:
            - '6379:6379'
        command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
        volumes:
            - redis-data:/data
        healthcheck:
            test: ['CMD', 'redis-cli', 'ping']
            interval: 5s
            timeout: 3s
            retries: 5
            start_period: 10s
        networks:
            - workflow-network

    api:
        build:
            context: .
            dockerfile: api/Dockerfile
        container_name: workflow-api
        ports:
            - '8000:8000'
        depends_on:
            kafka-init:
                condition: service_completed_successfully
            redis:
                condition: service_healthy
        environment:
            - REDIS_HOST=redis
            - REDIS_PORT=6379
            - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
            - LOG_LEVEL=INFO
        restart: unless-stopped
        networks:
            - workflow-network

    orchestrator:
        build:
            context: .
            dockerfile: orchestrator/Dockerfile
        container_name: workflow-orchestrator
        depends_on:
            kafka-init:
                condition: service_completed_successfully
            redis:
                condition: service_healthy
        environment:
            - REDIS_HOST=redis
            - REDIS_PORT=6379
            - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
            - LOG_LEVEL=INFO
        restart: unless-stopped
        networks:
            - workflow-network

    worker:
        build:
            context: .
            dockerfile: worker/Dockerfile
        depends_on:
            kafka-init:
                condition: service_completed_successfully
            redis:
                condition: service_healthy
        environment:
            - REDIS_HOST=redis
            - REDIS_PORT=6379
            - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
            - WORKER_ID=${WORKER_ID:-worker}
            - LOG_LEVEL=INFO
        restart: unless-stopped
        networks:
            - workflow-network
        deploy:
            replicas: ${WORKER_REPLICAS:-3}

networks:
    workflow-network:
        driver: bridge

volumes:
    kafka-data:
        driver: local
    redis-data:
        driver: local
